> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [xduwq.blog.csdn.net](https://xduwq.blog.csdn.net/article/details/127023461)  

[1、Diffusion models代码实战：从零搭建自己的扩散模型](https://blog.csdn.net/qq_41895747/article/details/125472027?spm=1001.2014.3001.5501 "1、Diffusion models代码实战：从零搭建自己的扩散模型")
==============================================================================================================================================================

> 这个系列曾经写过三篇文章专门讲代码，分别从数据集、[超参数](https://so.csdn.net/so/search?q=%E8%B6%85%E5%8F%82%E6%95%B0&spm=1001.2101.3001.7020)、loss设计、参数计算、Unet结构、正向过程、逆向过程等部分详细介绍了如何搭建DDPM。Diffusion models领域发展神速，最近半年代表作品有OpenAI的GLIDE、DALL-E 2，Google Brain的ImageGen，海森堡大学的Latent Diffusion。这篇博客针对入门新手讲解一下如何利用已有的资源快速搭建自己的Diffusion models。

[2、DDPM代码详细解读(1)：数据集准备、超参数设置、loss设计、关键参数计算](https://blog.csdn.net/qq_41895747/article/details/123660935 "2、DDPM代码详细解读(1)：数据集准备、超参数设置、loss设计、关键参数计算")
====================================================================================================================================================

> 大部分DDPM相关的论文代码都是基于《Denoising [Diffusion](https://so.csdn.net/so/search?q=Diffusion&spm=1001.2101.3001.7020) Probabilistic Models》和《Diffusion Models Beat GANs on Image Synthesis》贡献代码基础上小改动的。官方的DDPM是tensorflow TPU版本，暂时没有GPU的版本。本篇文章开始，详细解读一下pytorch和tensorflow版本的代码。

[3、DDPM代码详细解读(2)：Unet结构、正向和逆向过程、IS和FID测试、EMA优化](https://xduwq.blog.csdn.net/article/details/123678236 "3、DDPM代码详细解读(2)：Unet结构、正向和逆向过程、IS和FID测试、EMA优化")
======================================================================================================================================================

> 大部分DDPM相关的论文代码都是基于《Denoising Diffusion Probabilistic Models》和《Diffusion Models Beat GANs on Image Synthesis》贡献代码基础上小改动的。官方的DDPM是tensorflow TPU版本，暂时没有GPU的版本。上一篇文章介绍了数据集加载，超参数的含义、关键参数的计算方法等，这一篇重点解读一下网络结构。

[4、DDPM代码详细解读(3)：图解模型各部分结构、用ConvNextBlock代替Resnet](https://blog.csdn.net/qq_41895747/article/details/123790841 "4、DDPM代码详细解读(3)：图解模型各部分结构、用ConvNextBlock代替Resnet")
==================================================================================================================================================================

> 前两篇文章讲了pytorch版本的代码，并一一介绍重要方法的原理。官方给的代码是tensorflow TPU版本，没有跑通。但是有很多人用pytorch复现了tensorflow TPU版本的代码，暂时没看见tensorflow GPU版本的代码。这篇文章解读一下对应的pytorch版本的代码，重点分析一下用最新的ConvNextBlock代替ResBlock效果。

[5、手把手写Generative score-based models代码](https://blog.csdn.net/qq_41895747/article/details/126111392?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22126111392%22%2C%22source%22%3A%22qq_41895747%22%7D "5、手把手写Generative score-based models代码")
=========================================================================================================================================================================================================================================================================================

> 作为和DDPM同宗同源的score-based models，虽然没能做到如此火爆，但是其中很多思想都被后来的研究者们借鉴，这篇博客就详细讲解score-based models代码，手把手带读者生成自己的MNIST。

[6、如何用Diffusion models做interpolation插值任务？——原理解析和代码实战](https://blog.csdn.net/qq_41895747/article/details/125563672 "6、如何用Diffusion models做interpolation插值任务？——原理解析和代码实战")
========================================================================================================================================================================

> 很多Diffusion models的论文里都演示了[插值](https://so.csdn.net/so/search?q=%E6%8F%92%E5%80%BC&spm=1001.2101.3001.7020 "插值")任务，今天我们讲解一下如何用DDIM/DDPM做interpolation任务，剖析原理，并给出代码讲解与实战。

[7、详细解读Latent Diffusion Models：原理和代码](https://blog.csdn.net/qq_41895747/article/details/126311932 "7、详细解读Latent Diffusion Models：原理和代码")
========================================================================================================================================

> CVPR 2022中的一项新工作latent diffusion models引起了广泛关注，提出了两段式diffusion models能有效节省计算资源，latent attention技术为通用image-to-image任务打下基础，让人耳目一新，具有极强的借鉴意义和启发性，值得深度阅读。

[8、代码讲解——用diffusion models级联式超分辨重建](https://blog.csdn.net/qq_41895747/article/details/122813827?spm=1001.2014.3001.5501 "8、代码讲解——用diffusion models级联式超分辨重建")
============================================================================================================================================================

> 去年写过一篇文章《Diffusion Models在超分辨率领域的应用》，介绍diffusion models超分辨率重建方面工作。如今级联法已经成为diffusion models大模型的标配，主要原因有两点：1）直接训练256*256设置512*512分辨率的模型，硬件能力无法胜任。2）diffusion models超分模型已经能取得非常棒的效果，而且用相同的信息注入方式，完美贴合各种多模态任务。

[9、DDIM代码详细解读(1)：数据集加载、类别条件信息读取、关键超参数解析](https://blog.csdn.net/qq_41895747/article/details/125730056?spm=1001.2014.3001.5501 "9、DDIM代码详细解读(1)：数据集加载、类别条件信息读取、关键超参数解析")
======================================================================================================================================================================

> 之前写过三篇详细解读DDPM代码的博客，随着时间已经来到2022年7月，单纯使用DDPM已经逐渐被淘汰，最新的论文更多使用DDPM的改进版本。DDIM作为DDPM最重要的改进版本之一，从本篇博客开始详细解读一下DDIM代码。本文主要讲解如何加载数据集，如何读取类别条件信息，以及关键的超参数如何计算。

[10、DDIM代码详细解读(2)：关键参数计算、损失函数设计、添加时间步长信息、归一化设计](https://blog.csdn.net/qq_41895747/article/details/126608169?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22126608169%22%2C%22source%22%3A%22qq_41895747%22%7D "10、DDIM代码详细解读(2)：关键参数计算、损失函数设计、添加时间步长信息、归一化设计")
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

> 之前写过三篇详细解读DDPM代码的博客，随着时间已经来到2022年7月，单纯使用DDPM已经逐渐被淘汰，最新的论文更多使用DDPM的改进版本。DDIM作为DDPM最重要的改进版本之一，从本篇博客开始详细解读一下DDIM代码。这篇博客详细讲解一下如何计算关键参数，如何设计损失函数，如何添加时间步长信息，如何设计损失函数。

[11、DDIM代码详细解读(3)：核心采样代码、超分辨率重建](https://blog.csdn.net/qq_41895747/article/details/127603689?spm=1001.2014.3001.5501 "11、DDIM代码详细解读(3)：核心采样代码、超分辨率重建")
------------------------------------------------------------------------------------------------------------------------------------------------------

> 之前写过三篇详细解读DDPM代码的博客，随着时间已经来到2022年10月，单纯使用DDPM已经逐渐被淘汰，最新的论文更多使用DDPM的改进版本。DDIM作为DDPM最重要的改进版本之一，从本篇博客开始详细解读一下DDIM代码。这篇博客详细讲解一下如何设计核心采样代码、 如何用diffusion models做超分辨重建。

[12、DDIM代码详细解读(4)：分类器classifier的网络设计、训练、推理](https://blog.csdn.net/qq_41895747/article/details/127141502?spm=1001.2014.3001.5501 "12、DDIM代码详细解读(4)：分类器classifier的网络设计、训练、推理 ")
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

> 之前写过三篇详细解读DDPM代码的博客，随着时间已经来到2022年11月，单纯使用DDPM已经逐渐被淘汰，最新的论文更多使用DDPM的改进版本。DDIM作为DDPM最重要的改进版本之一，从本篇博客开始详细解读一下DDIM代码。这篇博客详细讲解一下如何设计分类器，如何训练分类器，如何在推理过程中使用分类器。

[13、深入解读GLIDE/PITI代码](https://xduwq.blog.csdn.net/article/details/126508201 "13、深入解读GLIDE/PITI代码")
--------------------------------------------------------------------------------------------------

> GLIDE是diffusion models text-to-image的一项非常经典的模型，PITI是一项基于GLIDE的工作，读懂PITI相当于读懂GLIDE，这篇文章就和读者一起解读代码，难以描述的地方会画出程序流程图解释。点赞打卡，立马启程！

[14、如何定制属于自己的stable diffusion？Dreambooth原理详解和代码实战](https://blog.csdn.net/qq_41895747/article/details/130386898 "14、如何定制属于自己的stable diffusion？Dreambooth原理详解和代码实战")
------------------------------------------------------------------------------------------------------------------------------------------------------------------

> AIGC大模型(如stable diffusion models)的训练成本已经超过绝大多数人的承受范围，彻底沦为中大厂/科研大组的“御用品”，这也是大模型时代的必然趋势。如何利用已有的开源大模型，微调出属于自己的专有模型？如何定制化自己专属扩散模型？这些问题无疑让我们这些没有资源直接训练达模型的人感到兴奋！dreambooth这篇论文出现的非常早，去年就已经大火过。经过时间的沉淀，现在定制化自己的diffusion大模型基本只剩下Dreambooth、textual inversion、LORA和Hypernetworks四种方法。笔者会依次带大家一一探索这些方法，一起玩转属于自己的diffusion！

[15、详细解读Diffuser DreamBooth代码](https://blog.csdn.net/qq_41895747/article/details/130813636 "15、详细解读Diffuser DreamBooth代码")
--------------------------------------------------------------------------------------------------------------------------

> 之前的博客[《如何定制属于自己的stable diffusion？Dreambooth原理详解和代码实战》](https://blog.csdn.net/qq_41895747/article/details/130386898?spm=1001.2014.3001.5501 "《如何定制属于自己的stable diffusion？Dreambooth原理详解和代码实战》")详细解读了dreambooth，不过那篇博客的代码讲解部分主要基于mmagic，不过瘾。这篇博客讲解一下diffuser的drembooth的部分。